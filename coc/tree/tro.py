import random
from concurrent.futures import ThreadPoolExecutor, as_completed
from coc.config import MAX_DEPTH, BRANCH_WIDTH
from coc.tree.une import CodeList, TreeNode, root_factory
from coc.tool.task import Task
from typing import Optional, List, Iterable
from coc.util.text import extract_code, extract_boxed
from coc.prompts.prompt_troi import prompts_2nd_person
from coc.prompts.prompt_une import build_trunk
from coc.tool.vqa import gemini_as_llm
from coc.util.misc import fulltask_to_task, set_seed
from coc.data.fulltask import FullTask
import textwrap

def generate_one_child(parent: TreeNode, suggestive_hint: str, llm) -> tuple[TreeNode, Optional[str]]:
    """
    Generate a single child node from a parent using a suggestive prompt.

    Args:
        parent: Parent node to expand from.
        suggestive_hint: Prompt to guide the AI's response.
        llm: Language model function.

    Returns:
        Tuple of (child node, answer if found, else None).
    """
    message = build_trunk(
        task=parent.codelist.env.get_var('task'),
        codes=parent.codelist.to_list_of_pair_of_str(),
        suggestive_hint=suggestive_hint,
        variant='neutral',
    )
    response = llm(message)
    codes = extract_code(response)
    answer = extract_boxed(response)

    # Ensure response contains either code or answer, but not both
    assert not (codes and answer), f"Both code and answer extracted: {response}"
    assert codes or answer, f"Neither code nor answer extracted: {response}"

    # Create a new child node
    child_codelist = parent.codelist.deepcopy()
    if answer:
        child = TreeNode(
            codelist=child_codelist,
            outputs=parent.outputs + [response],
            parent=parent,
            children=[],
            depth=parent.depth + 1
        )
        return child, answer
    else:
        for code in codes:
            child_codelist.append(code)
        child = TreeNode(
            codelist=child_codelist,
            outputs=parent.outputs + [response],
            parent=parent,
            children=[],
            depth=parent.depth + 1
        )
        return child, None

def generate_children(nodes_with_code: list[TreeNode], num_children: int, llm) -> tuple[list[TreeNode], list[tuple[TreeNode, str]]]:
    """
    Generate multiple child nodes in parallel from the given parent nodes.

    Args:
        nodes_with_code: List of parent nodes that have code (not answers).
        num_children: Number of children to generate (BRANCH_WIDTH).
        llm: Language model function.

    Returns:
        Tuple of (list of child nodes, list of (node, answer) pairs).
    """
    with ThreadPoolExecutor(max_workers=num_children) as executor:
        futures = []
        for _ in range(num_children):
            parent = random.choice(nodes_with_code)
            suggestive_hint = random.choice(prompts_2nd_person)
            futures.append(executor.submit(generate_one_child, parent, suggestive_hint, llm))

        children = []
        answers = []
        for future in as_completed(futures):
            child, answer = future.result()
            children.append(child)
            if answer:
                answers.append((child, answer))
        return children, answers

def evaluate(task: Task, llm) -> list[tuple[TreeNode, str]]:
    """
    Evaluate the task by building a branching tree with suggestive prompts.

    Each depth has BRANCH_WIDTH nodes, generated by randomly selecting parents from the previous depth
    and using random suggestive prompts as AI completion prefixes. Expands up to MAX_DEPTH.

    Args:
        task: The programming task to solve.
        llm: Language model function.

    Returns:
        List of (node, answer) pairs found during tree construction.
    """
    root = root_factory(task)
    current_depth_nodes = [root]
    all_answers = []

    for depth in range(1, MAX_DEPTH + 1):
        nodes_with_code = [
            node for node in current_depth_nodes
            if not node.outputs or not extract_boxed(node.outputs[-1])
        ]
        if not nodes_with_code:
            break
        children, answers = generate_children(nodes_with_code, BRANCH_WIDTH, llm)
        all_answers.extend(answers)
        current_depth_nodes = children

    return all_answers

def judge_multichoice(output: str, choices: List[str], answer: str) -> bool:
    """
    Judge if the output indicates the correct choice.

    Args:
        output: The extracted answer from the LLM.
        choices: List of possible choices.
        answer: The correct choice.

    Returns:
        True if the output can arrive at the correct choice, False otherwise.
    """
    ret = gemini_as_llm(textwrap.dedent(f'''
        judge the following output and return True if, given the choices available, the party offering this output has the capability of arriving at the correct choice,
            otherwise return False.
        output (cannot see the choices): {output}
        choices: {choices}
        answer (correct choice is): {answer}'''
    ))
    return 'False' not in ret and 'True' in ret

def eval_a_batch(batch: Iterable[FullTask], llm) -> tuple[int, int]:
    """
    Evaluate a batch of tasks using the tree search approach.

    For each task, builds a tree, collects answers, selects the most common answer,
    and checks its correctness.

    Args:
        batch: Iterable of FullTask objects.
        llm: Language model function.

    Returns:
        Tuple of (number of correct answers, total tasks).
    """
    correct = 0
    total = 0
    for fulltask in batch:
        task = fulltask_to_task(fulltask)
        answers_nodes = evaluate(task, llm)
        if answers_nodes:
            answers = [answer for _, answer in answers_nodes]
            most_common_answer = max(set(answers), key=answers.count)
            if judge_multichoice(most_common_answer, fulltask['choices'], fulltask['answer']):
                correct += 1
        total += 1
    return correct, total

if __name__ == '__main__':
    set_seed()
    from coc.data.zero import zero
    from coc.tree.llm import llm
    batch = zero(offer='sub')
    correct, total = eval_a_batch(batch, llm)
    print(f"Correct: {correct}, Total: {total}")